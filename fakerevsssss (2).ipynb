{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9723fadd-0da1-4069-b7ea-c201d5a6f5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1adbe0b6-efa8-446a-b663-f2950b35fe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- Preprocessing Functions -------------\n",
    "\n",
    "def clean_stopwords(text):\n",
    "    stopwordlist = ['a', 'about', 'above', 'after', 'again', 'ain', 'all', 'am', 'an',\n",
    "                   'and', 'any', 'are', 'as', 'at', 'be', 'because', 'been', 'before',\n",
    "                   'being', 'below', 'between', 'both', 'by', 'can', 'd', 'did', 'do',\n",
    "                   'does', 'doing', 'down', 'during', 'each', 'few', 'for', 'from',\n",
    "                   'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here',\n",
    "                   'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in',\n",
    "                   'into', 'is', 'it', 'its', 'itself', 'just', 'll', 'm', 'ma',\n",
    "                   'me', 'more', 'most', 'my', 'myself', 'now', 'o', 'of', 'on', 'once',\n",
    "                   'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'own', 're',\n",
    "                   's', 'same', 'she', \"shes\", 'should', \"shouldve\", 'so', 'some', 'such',\n",
    "                   't', 'than', 'that', \"thatll\", 'the', 'their', 'theirs', 'them',\n",
    "                   'themselves', 'then', 'there', 'these', 'they', 'this', 'those',\n",
    "                   'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was',\n",
    "                   'we', 'were', 'what', 'when', 'where', 'which', 'while', 'who', 'whom',\n",
    "                   'why', 'will', 'with', 'won', 'y', 'you', \"youd\", \"youll\", \"youre\",\n",
    "                   \"youve\", 'your', 'yours', 'yourself', 'yourselves']\n",
    "    STOPWORDS = set(stopwordlist)\n",
    "    return \" \".join([word for word in str(text).split() if word.lower() not in STOPWORDS])\n",
    "\n",
    "def clean_punctuations(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "def clean_repeating_characters(text):\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
    "\n",
    "def clean_URLs(text):\n",
    "    return re.sub(r\"((www\\.[^\\s]+)|(http\\S+))\", \"\", text)\n",
    "\n",
    "def clean_numeric(text):\n",
    "    return re.sub('[0-9]+', '', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ada364c-7418-45cf-86e4-17aed3521587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- Load the Pre-trained Model -------------\n",
    "\n",
    "@st.cache_resource  # Caches the model to prevent reloading on every interaction\n",
    "def load_model():\n",
    "    return tf.keras.models.load_model('fakerev.h5')\n",
    "\n",
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4f7f122-e38e-4cf1-953f-ac3a32ebbcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- Reconstruct the Tokenizer -------------\n",
    "\n",
    "def get_tokenizer():\n",
    "    # Define the tokenizer parameters as used during training\n",
    "    tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "    \n",
    "    # Reconstruct the word_index as used during training\n",
    "    word_index = {\n",
    "        'the': 1,\n",
    "        'and': 2,\n",
    "        'to': 3,\n",
    "        'of': 4,\n",
    "        'a': 5,\n",
    "        'in': 6,\n",
    "        'is': 7,\n",
    "        'it': 8,\n",
    "        'you': 9,\n",
    "        'that': 10,\n",
    "        # ... (Add all words used during training)\n",
    "    }\n",
    "    \n",
    "    # Assign the word_index to the tokenizer\n",
    "    tokenizer.word_index = word_index\n",
    "    \n",
    "    return tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b37dae3-9742-416d-af45-cd5febd52858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- Preprocessing Function -------------\n",
    "\n",
    "def preprocess_text(text, tokenizer, max_length):\n",
    "    if text is None or text.strip() == \"\":\n",
    "        return None\n",
    "\n",
    "    text = text.lower()\n",
    "    text = clean_stopwords(text)\n",
    "    # Optionally uncomment to clean punctuations\n",
    "    # text = clean_punctuations(text)\n",
    "    text = clean_repeating_characters(text)\n",
    "    text = clean_URLs(text)\n",
    "    text = clean_numeric(text)\n",
    "    \n",
    "    sequences = tokenizer.texts_to_sequences([text])\n",
    "    \n",
    "    if len(sequences[0]) == 0:\n",
    "        return None\n",
    "    \n",
    "    padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9aa2160-6cbf-451e-82f5-d1f028fb8976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- Streamlit Interface -------------\n",
    "\n",
    "st.title(\"Fake Review Detection\")\n",
    "\n",
    "st.write(\"\"\"\n",
    "### Enter a review below, and the model will predict whether it's computer-generated or human-generated.\n",
    "\"\"\")\n",
    "\n",
    "# Text input\n",
    "input_text = st.text_area(\"Enter the review text:\", height=200)\n",
    "\n",
    "# Prediction button\n",
    "if st.button(\"Predict\"):\n",
    "    if input_text.strip():\n",
    "        # Define the maximum sequence length (must match training)\n",
    "        max_sequence_length = 200  # Example value; replace with actual value used during training\n",
    "        \n",
    "        # Preprocess the input text\n",
    "        processed_text = preprocess_text(input_text, tokenizer, max_sequence_length)\n",
    "        \n",
    "        if processed_text is None:\n",
    "            st.error(\"The input text is invalid or cannot be processed. Please try again with different text.\")\n",
    "        else:\n",
    "            # Make prediction\n",
    "            prediction = model.predict(processed_text)\n",
    "            \n",
    "            # Define classification threshold\n",
    "            threshold = 0.76  # As per your user code\n",
    "            \n",
    "            # Interpret the prediction\n",
    "            classify = {1: \"Computer Generated\", 0: \"Original Resource\"}\n",
    "            predicted_class = (prediction > threshold).astype(int)\n",
    "            predicted_label = classify[predicted_class[0][0]]\n",
    "            \n",
    "            # Display the result\n",
    "            st.success(f\"**Predicted class:** {predicted_label}\")\n",
    "            st.write(f\"**Prediction Probability:** {prediction[0][0]:.4f}\")\n",
    "    else:\n",
    "        st.warning(\"Please enter some text to analyze.\")\n",
    "\n",
    "# ------------- Instructions -------------\n",
    "\n",
    "st.sidebar.header(\"Instructions\")\n",
    "st.sidebar.write(\"\"\"\n",
    "1. **Enter the Review Text**: Input the review you want to analyze in the text area.\n",
    "2. **Predict**: Click the \"Predict\" button to see the result.\n",
    "3. **Result**: The app will display whether the review is computer-generated or human-generated along with the prediction probability.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fef88a-e7ec-4f3f-9ed7-43e180617155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d27979-6479-419e-8333-29fcc0a03164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efd19e9-fdab-41e2-932b-a34c9cd68a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
